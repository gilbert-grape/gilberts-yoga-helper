# Story: Crawl-Fortschrittsanzeige mit ZeitschÃ¤tzung

## Ãœbersicht

**Als** Benutzer des Gebrauchtwaffen Aggregators
**mÃ¶chte ich** wÃ¤hrend eines Crawls sehen, wie weit der Fortschritt ist und wie lange es noch dauert
**damit** ich weiÃŸ, ob ich warten soll oder spÃ¤ter wiederkommen kann

## Akzeptanzkriterien

### AC1: Fortschrittsanzeige
- [ ] Anzeige "X von Y Quellen" wÃ¤hrend des Crawls
- [ ] Visueller Fortschrittsbalken (z.B. `â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘`)
- [ ] Aktuell verarbeitete Quelle wird angezeigt

### AC2: ZeitschÃ¤tzung (ETA)
- [ ] GeschÃ¤tzte Restzeit in groben Minuten anzeigen ("ca. 3 Min")
- [ ] Keine falsche PrÃ¤zision (keine Sekunden)

### AC3: Intelligente Berechnung
- [ ] **Mit Historie (â‰¥3 Crawls):** Durchschnitt der letzten 3 erfolgreichen Crawl-Dauern verwenden
- [ ] **Ohne Historie (<3 Crawls):** Echtzeit-Berechnung: `(elapsed / sources_done) * sources_remaining`
- [ ] Nur erfolgreiche Crawls (`is_success == True`) fÃ¼r Historie berÃ¼cksichtigen

### AC4: Crawl-Historie speichern
- [ ] Neue Tabelle `crawl_runs` mit: `id`, `started_at`, `completed_at`, `duration_seconds`, `sources_attempted`, `sources_succeeded`, `is_success`
- [ ] Nach jedem Crawl einen Eintrag erstellen

## Technische Details

### Backend-Ã„nderungen

**1. Neues Datenbankmodell `CrawlRun`:**
```python
class CrawlRun(Base):
    __tablename__ = "crawl_runs"
    id = Column(Integer, primary_key=True)
    started_at = Column(DateTime, nullable=False)
    completed_at = Column(DateTime, nullable=False)
    duration_seconds = Column(Float, nullable=False)
    sources_attempted = Column(Integer, default=0)
    sources_succeeded = Column(Integer, default=0)
    is_success = Column(Boolean, default=False)
```

**2. CrawlState erweitern:**
```python
@dataclass
class CrawlState:
    # ... bestehende Felder ...
    sources_total: int = 0
    sources_done: int = 0
    started_at: Optional[datetime] = None
```

**3. Neue CRUD-Funktionen:**
- `save_crawl_run(session, result: CrawlResult)` - Speichert Crawl-Durchgang
- `get_avg_crawl_duration(session, limit=3)` - Holt Durchschnitt der letzten N erfolgreichen Crawls

**4. `/admin/crawl/status` Endpoint erweitern:**
- `sources_total`, `sources_done`, `started_at` zurÃ¼ckgeben
- `avg_duration` (historischer Durchschnitt) zurÃ¼ckgeben

### Frontend-Ã„nderungen

**JavaScript ETA-Berechnung:**
```javascript
function calculateETA(data) {
    const elapsed = (Date.now() - new Date(data.started_at)) / 1000;

    if (data.avg_duration && data.avg_duration > 0) {
        // Historische Berechnung
        const remaining = Math.max(0, data.avg_duration - elapsed);
        return Math.ceil(remaining / 60);
    } else if (data.sources_done > 0) {
        // Echtzeit-Berechnung
        const perSource = elapsed / data.sources_done;
        const remaining = perSource * (data.sources_total - data.sources_done);
        return Math.ceil(remaining / 60);
    }
    return null;
}
```

**UI-Darstellung:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”„ Crawl lÃ¤uft...                          â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  5/13 Quellen     â”‚
â”‚                                             â”‚
â”‚  Aktuell: waffenboerse.ch                   â”‚
â”‚  â±ï¸ Noch ca. 3 Minuten                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Aufwand-SchÃ¤tzung

- Backend (Model, CRUD, State): ~1-2 Stunden
- Migration: ~15 Minuten
- Frontend (JS, HTML): ~1 Stunde
- Tests: ~1 Stunde

**Gesamt: ~4 Stunden**

## AbhÃ¤ngigkeiten

- Bestehende Crawl-Infrastruktur (`CrawlState`, `CrawlResult`)
- Admin-Template `crawl_admin.html`
- SQLAlchemy/Alembic fÃ¼r Migration
